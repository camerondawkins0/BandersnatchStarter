{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "## Highest Model Score: 92.80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600,)\n",
      "(600,)\n",
      "Accuracy: 0.9283333333333333\n",
      "Baseline: 0.30133333333333334\n"
     ]
    }
   ],
   "source": [
    "from data import Database\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "db = Database()\n",
    "# db.reset()\n",
    "# db.seed(3000)\n",
    "\n",
    "df = db.dataframe()\n",
    "\n",
    "# Find Baseline\n",
    "baseline = df['Rarity'].value_counts(normalize=True).max()\n",
    "\n",
    "# Create features and target\n",
    "target = \"Rarity\"\n",
    "X = df.drop(columns=[target, 'Name', 'Type', 'Damage', 'Roll', 'Level'])\n",
    "y = df[target]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_jobs=-1,\n",
    "                               random_state=42)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = np.array(model.predict(x_test))\n",
    "\n",
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\\nBaseline: {baseline}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [5, 10, 25, 40, 55, 70, 85, 100],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [5, 10, 25, 40, 55, 70, 85, 100],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [5, 10, 25, 40, 55, 70, 85, 100],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 25, 40, 55, 70, 85, 100],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n",
      "{'max_depth': 25, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_estimator_.score(x_test, y_test))\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Fortuna import random_float, random_int\n",
    "from MonsterLab.monster_data import Random\n",
    "import pandas as pd\n",
    "from damage_parser import parse_damage\n",
    "\n",
    "rand = Random()\n",
    "# Retrain the model with the best_params.\n",
    "model_trained = RandomForestClassifier(n_estimators=best_params['n_estimators'],\n",
    "                                       max_depth=best_params['max_depth'],\n",
    "                                       min_samples_split=best_params['min_samples_split'],\n",
    "                                       n_jobs=-1,\n",
    "                                       random_state=42)\n",
    "\n",
    "model_trained.fit(x_train, y_train)\n",
    "\n",
    "options = [\"Health\", \"Energy\", \"Sanity\", \"Low\", \"High\", \"Rarity\"]\n",
    "stats = [round(random_float(1, 250), 2) for _ in range(3)]\n",
    "level = random_int(1, 84)\n",
    "health = stats.pop()\n",
    "energy = stats.pop()\n",
    "sanity = stats.pop()\n",
    "damage = f\"{level}d{rand.dice[rand.random_rank()]}{rand.bonus()}\"\n",
    "low, high, _ = parse_damage(damage)\n",
    "\n",
    "data = pd.DataFrame([dict(zip(options, (health, energy, sanity, low, high)))])\n",
    "\n",
    "prediction = model.predict(data)\n",
    "\n",
    "proba_pred = model.predict_proba(data).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9283333333333333\n",
      "Baseline: 0.30133333333333334\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array(model.predict(x_test))\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\\nBaseline: {baseline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Rank 1\n",
      "Confidence: 40.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prediction: Rank {prediction[0]}\\nConfidence: {proba_pred*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 5), (2400,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "## Highest Model Score: 94.83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 2s 23ms/step - loss: 3.6750 - accuracy: 0.1646 - val_loss: 2.6270 - val_accuracy: 0.1833\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1351 - accuracy: 0.2179 - val_loss: 1.8131 - val_accuracy: 0.3083\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.6039 - accuracy: 0.4750 - val_loss: 1.5055 - val_accuracy: 0.4917\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4325 - accuracy: 0.5350 - val_loss: 1.3995 - val_accuracy: 0.5417\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3844 - accuracy: 0.5421 - val_loss: 1.3731 - val_accuracy: 0.5283\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3670 - accuracy: 0.5462 - val_loss: 1.3624 - val_accuracy: 0.5617\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 1.3539 - accuracy: 0.5767 - val_loss: 1.3498 - val_accuracy: 0.5750\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.3387 - accuracy: 0.5838 - val_loss: 1.3248 - val_accuracy: 0.5650\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3201 - accuracy: 0.5667 - val_loss: 1.3116 - val_accuracy: 0.5700\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3043 - accuracy: 0.5754 - val_loss: 1.2984 - val_accuracy: 0.5783\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.2897 - accuracy: 0.5779 - val_loss: 1.2940 - val_accuracy: 0.5817\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 1.2766 - accuracy: 0.5808 - val_loss: 1.2736 - val_accuracy: 0.5750\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.2635 - accuracy: 0.5733 - val_loss: 1.2532 - val_accuracy: 0.5700\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.2492 - accuracy: 0.5713 - val_loss: 1.2350 - val_accuracy: 0.5350\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.2311 - accuracy: 0.5658 - val_loss: 1.2087 - val_accuracy: 0.5583\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.1924 - accuracy: 0.5429 - val_loss: 1.1533 - val_accuracy: 0.4600\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1440 - accuracy: 0.5325 - val_loss: 1.0993 - val_accuracy: 0.5467\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 1.0983 - accuracy: 0.5312 - val_loss: 1.0498 - val_accuracy: 0.5467\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.0562 - accuracy: 0.5421 - val_loss: 1.0012 - val_accuracy: 0.5233\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.0154 - accuracy: 0.4867 - val_loss: 0.9579 - val_accuracy: 0.5800\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.9733 - accuracy: 0.5967 - val_loss: 0.9010 - val_accuracy: 0.5867\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.9180 - accuracy: 0.6350 - val_loss: 0.8474 - val_accuracy: 0.6933\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.8648 - accuracy: 0.7054 - val_loss: 0.7933 - val_accuracy: 0.7233\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.8136 - accuracy: 0.7192 - val_loss: 0.7010 - val_accuracy: 0.7467\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6959 - accuracy: 0.7596 - val_loss: 0.6038 - val_accuracy: 0.8217\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6188 - accuracy: 0.8096 - val_loss: 0.5487 - val_accuracy: 0.8333\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5837 - accuracy: 0.8271 - val_loss: 0.5201 - val_accuracy: 0.8233\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5569 - accuracy: 0.8296 - val_loss: 0.4955 - val_accuracy: 0.8317\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.5346 - accuracy: 0.8350 - val_loss: 0.4688 - val_accuracy: 0.8483\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5152 - accuracy: 0.8404 - val_loss: 0.4652 - val_accuracy: 0.8600\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4954 - accuracy: 0.8442 - val_loss: 0.4481 - val_accuracy: 0.8900\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.4811 - accuracy: 0.8500 - val_loss: 0.4285 - val_accuracy: 0.8550\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.8525 - val_loss: 0.4113 - val_accuracy: 0.8717\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.8621 - val_loss: 0.4480 - val_accuracy: 0.8617\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4528 - accuracy: 0.8596 - val_loss: 0.4027 - val_accuracy: 0.8700\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4402 - accuracy: 0.8600 - val_loss: 0.3867 - val_accuracy: 0.8933\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4217 - accuracy: 0.8696 - val_loss: 0.3754 - val_accuracy: 0.8967\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.8675 - val_loss: 0.3736 - val_accuracy: 0.8917\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8629 - val_loss: 0.3824 - val_accuracy: 0.8700\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4045 - accuracy: 0.8746 - val_loss: 0.3539 - val_accuracy: 0.9050\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.3906 - accuracy: 0.8746 - val_loss: 0.3512 - val_accuracy: 0.8967\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3813 - accuracy: 0.8800 - val_loss: 0.3401 - val_accuracy: 0.9033\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8804 - val_loss: 0.3325 - val_accuracy: 0.9067\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3667 - accuracy: 0.8817 - val_loss: 0.3279 - val_accuracy: 0.9083\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3604 - accuracy: 0.8871 - val_loss: 0.3221 - val_accuracy: 0.9067\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.3547 - accuracy: 0.8883 - val_loss: 0.3174 - val_accuracy: 0.9050\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.8908 - val_loss: 0.3115 - val_accuracy: 0.9083\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3441 - accuracy: 0.8896 - val_loss: 0.3087 - val_accuracy: 0.9083\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3420 - accuracy: 0.8921 - val_loss: 0.3065 - val_accuracy: 0.9033\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3331 - accuracy: 0.8917 - val_loss: 0.3012 - val_accuracy: 0.9133\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3246 - accuracy: 0.8950 - val_loss: 0.2897 - val_accuracy: 0.9183\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3213 - accuracy: 0.8958 - val_loss: 0.2790 - val_accuracy: 0.9167\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.3015 - accuracy: 0.9042 - val_loss: 0.2752 - val_accuracy: 0.9167\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3003 - accuracy: 0.9046 - val_loss: 0.2662 - val_accuracy: 0.9167\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2947 - accuracy: 0.9054 - val_loss: 0.2714 - val_accuracy: 0.9233\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2913 - accuracy: 0.9071 - val_loss: 0.2662 - val_accuracy: 0.9083\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2851 - accuracy: 0.9100 - val_loss: 0.2546 - val_accuracy: 0.9183\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.2780 - accuracy: 0.9162 - val_loss: 0.2431 - val_accuracy: 0.9283\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2701 - accuracy: 0.9112 - val_loss: 0.2395 - val_accuracy: 0.9217\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2640 - accuracy: 0.9142 - val_loss: 0.2399 - val_accuracy: 0.9350\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2625 - accuracy: 0.9167 - val_loss: 0.2453 - val_accuracy: 0.9083\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2554 - accuracy: 0.9150 - val_loss: 0.2235 - val_accuracy: 0.9300\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2412 - accuracy: 0.9237 - val_loss: 0.2226 - val_accuracy: 0.9267\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2400 - accuracy: 0.9271 - val_loss: 0.2184 - val_accuracy: 0.9367\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2365 - accuracy: 0.9254 - val_loss: 0.2117 - val_accuracy: 0.9350\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2299 - accuracy: 0.9262 - val_loss: 0.2098 - val_accuracy: 0.9400\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2267 - accuracy: 0.9296 - val_loss: 0.2053 - val_accuracy: 0.9383\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2243 - accuracy: 0.9308 - val_loss: 0.2039 - val_accuracy: 0.9350\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2286 - accuracy: 0.9225 - val_loss: 0.2163 - val_accuracy: 0.9233\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2291 - accuracy: 0.9292 - val_loss: 0.2038 - val_accuracy: 0.9400\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2149 - accuracy: 0.9329 - val_loss: 0.1974 - val_accuracy: 0.9333\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2142 - accuracy: 0.9321 - val_loss: 0.1919 - val_accuracy: 0.9383\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2068 - accuracy: 0.9362 - val_loss: 0.1965 - val_accuracy: 0.9500\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2097 - accuracy: 0.9333 - val_loss: 0.1914 - val_accuracy: 0.9333\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2045 - accuracy: 0.9342 - val_loss: 0.1864 - val_accuracy: 0.9433\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1991 - accuracy: 0.9404 - val_loss: 0.1860 - val_accuracy: 0.9367\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1965 - accuracy: 0.9404 - val_loss: 0.1822 - val_accuracy: 0.9467\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.1927 - accuracy: 0.9429 - val_loss: 0.1799 - val_accuracy: 0.9400\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.1898 - accuracy: 0.9433 - val_loss: 0.1767 - val_accuracy: 0.9450\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.1873 - accuracy: 0.9454 - val_loss: 0.1773 - val_accuracy: 0.9400\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1896 - accuracy: 0.9396 - val_loss: 0.1738 - val_accuracy: 0.9483\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1843 - accuracy: 0.9446 - val_loss: 0.1719 - val_accuracy: 0.9450\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1882 - accuracy: 0.9400 - val_loss: 0.1903 - val_accuracy: 0.9283\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1876 - accuracy: 0.9413 - val_loss: 0.1723 - val_accuracy: 0.9500\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1779 - accuracy: 0.9450 - val_loss: 0.1661 - val_accuracy: 0.9467\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1773 - accuracy: 0.9433 - val_loss: 0.1796 - val_accuracy: 0.9333\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.1778 - accuracy: 0.9429 - val_loss: 0.1678 - val_accuracy: 0.9500\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1782 - accuracy: 0.9438 - val_loss: 0.1659 - val_accuracy: 0.9483\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1743 - accuracy: 0.9463 - val_loss: 0.1683 - val_accuracy: 0.9400\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1727 - accuracy: 0.9458 - val_loss: 0.1630 - val_accuracy: 0.9550\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1663 - accuracy: 0.9500 - val_loss: 0.1603 - val_accuracy: 0.9517\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1643 - accuracy: 0.9488 - val_loss: 0.1558 - val_accuracy: 0.9500\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1638 - accuracy: 0.9475 - val_loss: 0.1556 - val_accuracy: 0.9517\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1630 - accuracy: 0.9483 - val_loss: 0.1557 - val_accuracy: 0.9500\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1646 - accuracy: 0.9492 - val_loss: 0.1614 - val_accuracy: 0.9383\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.1596 - accuracy: 0.9492 - val_loss: 0.1567 - val_accuracy: 0.9483\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model_tf = Sequential([\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model_tf.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer=Adam(learning_rate=0.001),\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "history = model_tf.fit(x_train, y_train, batch_size=200,\n",
    "                       epochs=200,\n",
    "                       callbacks=[callback],\n",
    "                       validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.949999988079071\n",
      "Validation Accuracy: 0.9549999833106995\n"
     ]
    }
   ],
   "source": [
    "accuracy = max(history.history['accuracy'])\n",
    "val_accuracy = max(history.history['val_accuracy'])\n",
    "print(f\"Accuracy: {accuracy}\\nValidation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9483\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_tf.evaluate(x_test, y_test, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.9483333230018616\n",
      "Evaluation Loss: 0.15672776103019714\n"
     ]
    }
   ],
   "source": [
    "print(f\"Evaluation Accuracy: {accuracy}\\nEvaluation Loss: {loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
